{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for model training\n",
    "\n",
    "### Training Flow\n",
    "\n",
    "Load Training Data:\n",
    "- Load set of input data and label files\n",
    "- Prefilter positive set only to rule out heavily-masked patches\n",
    "- Create train/test set\n",
    "- Define augmentation parameters\n",
    "\n",
    "Train Model:\n",
    "- Define model architecture\n",
    "- Compile model\n",
    "- Train and evaluate model\n",
    "- Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "parent_dir = os.path.split(os.getcwd())[0]\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "from scripts import viz_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 64\n",
    "\n",
    "data_files = [\n",
    "    'random_land_clay_centroids_2023-01-01_2023-12-31_patch_arrays.pkl', \n",
    "    'active_surface_mines_2023-01-01_2023-12-31_patch_arrays.pkl',\n",
    "    'v0.1_negatives_2023-01-01_2023-12-31_patch_arrays.pkl'\n",
    "    ]\n",
    "label_files = [\n",
    "    'random_land_clay_centroids_2023-01-01_2023-12-31_patch_array_labels.pkl', \n",
    "    'active_surface_mines_2023-01-01_2023-12-31_patch_array_labels.pkl', \n",
    "    'v0.1_negatives_2023-01-01_2023-12-31_patch_array_labels.pkl'\n",
    "    ]\n",
    "\n",
    "patches = []\n",
    "labels = []\n",
    "\n",
    "data_dir = os.path.join('..', 'data', 'training_data', f\"{resolution}_px\")\n",
    "\n",
    "for data, label in tqdm(zip(data_files, label_files), total=len(data_files)):\n",
    "    with open(os.path.join(data_dir, data), 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        for elem in data:\n",
    "            #patch = dl_utils.pad_patch(elem, resolution)\n",
    "            patches.append(elem)\n",
    "    with open(os.path.join(data_dir, label), 'rb') as f:\n",
    "        label = pickle.load(f)\n",
    "        labels = np.concatenate((labels, label))\n",
    "\n",
    "patches = np.array(patches)\n",
    "positive_patches = patches[labels == 1]\n",
    "negative_patches = patches[labels == 0]\n",
    "\n",
    "print(len(patches), \"samples loaded\")\n",
    "print(sum(labels == 1), \"positive samples\")\n",
    "print(sum(labels == 0), \"negative samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 64\n",
    "indices = np.random.randint(0, len(patches), num_samples)\n",
    "viz_tools.plot_image_grid(patches[indices], labels=[int(label) for label in labels[indices]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_white(data, threshold, return_rejects=True):\n",
    "    \"\"\"Filter out patches that are mostly white.\n",
    "    \n",
    "    Args:\n",
    "        data (np.array): Array of patches.\n",
    "        threshold (float): Threshold for white pixels.\n",
    "        return_rejects (bool): If True, return the rejected patches.\n",
    "        \n",
    "    Returns:\n",
    "        np.array: Filtered patches.\n",
    "        np.array: Rejected patches (if return_rejects is True).\n",
    "    \"\"\"\n",
    "    rejects = []\n",
    "    for i, patch in enumerate(data):\n",
    "        if np.median(patch[:,:,1]) > threshold:\n",
    "            rejects.append(i)\n",
    "    if return_rejects:\n",
    "        return np.delete(data, rejects, axis=0), data[rejects]\n",
    "    else:\n",
    "        return np.delete(data, rejects, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter positive pixels that are masked beyond a threshold. Don't want to give positive examples of cloud-masked patches\n",
    "filtered_positives, positive_rejects = filter_white(positive_patches, threshold= 2_500, return_rejects=True)\n",
    "if len(positive_rejects) > 0:\n",
    "    num_samples = 16**2\n",
    "    if len(positive_rejects) < num_samples:\n",
    "        num_samples = len(positive_rejects)\n",
    "    indices = np.random.randint(0, len(positive_rejects), num_samples)\n",
    "    viz_tools.plot_numpy_grid(positive_rejects[indices,:,:,3:0:-1] / 3000)\n",
    "    plt.title(\"Positive Masked Rejects\")\n",
    "    plt.show()\n",
    "\n",
    "num_samples = 25 ** 2\n",
    "indices = np.random.randint(0, len(filtered_positives), num_samples)\n",
    "fig = viz_tools.plot_numpy_grid(filtered_positives[indices,:,:,3:0:-1] / 3000)\n",
    "plt.title('Positive Filtered Samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_negatives, negative_rejects = filter_white(positive_patches, threshold= 2_500, return_rejects=True)\n",
    "if len(negative_rejects) > 0:\n",
    "    num_samples = 16**2\n",
    "    if len(positive_rejects) < num_samples:\n",
    "        num_samples = len(positive_rejects)\n",
    "    indices = np.random.randint(0, len(negative_rejects), num_samples)\n",
    "    viz_tools.plot_numpy_grid(negative_rejects[indices,:,:,3:0:-1] / 3000)\n",
    "    plt.title(\"Negative Mask Rejects\")\n",
    "    plt.show()\n",
    "\n",
    "num_samples = 25 ** 2\n",
    "indices = np.random.randint(0, len(filtered_negatives), num_samples)\n",
    "fig = viz_tools.plot_numpy_grid(filtered_negatives[indices,:,:,3:0:-1] / 3000)\n",
    "plt.title('Negative Filtered Samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for RGBIR, x = normalize(np.copy(images[:,:,:,[1,2,3,8]]))\n",
    "x = patches\n",
    "y = labels\n",
    "x, y = shuffle(x, y, random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "Augmentation is important to help the model train. These are parameters that generally worked, but there is certainly room for improvement.\n",
    "\n",
    "Plot a set of images to give an example of augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_parameters = {\n",
    "    'featurewise_center': False,\n",
    "    'rotation_range': 360,\n",
    "    'width_shift_range': [0.9, 1.1],\n",
    "    'height_shift_range': [0.9, 1.1],\n",
    "    'shear_range': 10,\n",
    "    'zoom_range': [0.9, 1.1],\n",
    "    'vertical_flip': True,\n",
    "    'horizontal_flip': True,\n",
    "    # Fill options: \"constant\", \"nearest\", \"reflect\" or \"wrap\"\n",
    "    'fill_mode': 'reflect'\n",
    "}\n",
    "\n",
    "datagen = ImageDataGenerator(**augmentation_parameters)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,12), facecolor=(1,1,1), dpi=150)\n",
    "aug_img, aug_labels = datagen.flow(x, y, batch_size=64).next()\n",
    "viz_tools.plot_image_grid(aug_img, labels=[int(l) for l in aug_labels], norm=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm = np.clip(np.array(x.astype(\"float32\") / 10000), 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_norm, y, test_size=0.30)\n",
    "print(f\"Min Value:\\t\\t {np.min(x_train):.3f}\")\n",
    "print(f\"Max Value:\\t\\t {np.max(x_train):.3f}\")\n",
    "print(f\"Median Value:\\t\\t {np.median(x_train):.3f}\")\n",
    "print(\"Num Train:\\t\\t\", len(x_train))\n",
    "print(\"Num Test:\\t\\t\", len(x_test))\n",
    "print(f\"Percent Negative Train:\\t {100 * sum(y_train == 0.0) / len(y_train):.1f}\")\n",
    "print(f\"Percent Negative Test:\\t {100 * sum(y_test == 0.0) / len(y_test):.1f}\")\n",
    "\n",
    "num_classes = 2\n",
    "input_shape = x_train.shape[1:]\n",
    "print(\"Input Shape:\", input_shape)\n",
    "\n",
    "model = keras.Sequential([\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3), padding='same', activation=\"relu\"),\n",
    "        layers.Conv2D(32, kernel_size=(3), padding='same', activation=\"relu\"),\n",
    "        layers.Conv2D(32, kernel_size=(3), padding='same', activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2)),\n",
    "        layers.Conv2D(32, kernel_size=(3), padding='same', activation=\"relu\"),\n",
    "        layers.Conv2D(32, kernel_size=(3), padding='same', activation=\"relu\"),\n",
    "        layers.Conv2D(32, kernel_size=(3), padding='same', activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2)),\n",
    "        layers.Conv2D(32, kernel_size=(3), padding='same', activation=\"relu\"),\n",
    "        layers.Conv2D(32, kernel_size=(3), padding='same', activation=\"relu\"),\n",
    "        layers.Conv2D(32, kernel_size=(3), padding='same', activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(3)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(1, activation='sigmoid')])\n",
    "model.summary()\n",
    "model.compile(\n",
    "optimizer=keras.optimizers.Adam(3e-4), \n",
    "loss=keras.losses.BinaryCrossentropy(from_logits=False), \n",
    "metrics=[keras.metrics.BinaryAccuracy(name=\"acc\")])\n",
    "\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 64\n",
    "# add a weighted loss\n",
    "class_weight = {0: 1, 1: 1}\n",
    "\n",
    "model.fit(datagen.flow(x_train, y_train),\n",
    "        batch_size=batch_size, \n",
    "        epochs=epochs, \n",
    "        validation_data = (x_test, y_test),\n",
    "        verbose = 1,\n",
    "        shuffle=True,\n",
    "        class_weight = class_weight\n",
    "        )\n",
    "train_accuracy += model.history.history['acc']\n",
    "test_accuracy += model.history.history['val_acc']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,5), dpi=100, facecolor=(1,1,1))\n",
    "plt.plot([i for i in range(1, len(train_accuracy) + 1)], train_accuracy, label='Train Acc')\n",
    "plt.plot([i for i in range(1, len(train_accuracy) + 1)], test_accuracy, c='r', label='Val Acc')\n",
    "percent_negative = (sum(y_train == 0.0) / len(y_train))\n",
    "plt.plot([1, len(train_accuracy) + 1], [percent_negative, percent_negative], '--', c='gray', label='Baseline')\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Network Train and Val Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.8\n",
    "print(\"Test Set Metrics:\")\n",
    "preds = model.predict(x_test)\n",
    "print(classification_report(y_test, preds > threshold, \n",
    "                        target_names=['No Mine', 'Mine']))\n",
    "\n",
    "version_number = f'0.2'\n",
    "current_date = date.today()\n",
    "model_name = f\"{resolution}px_v{version_number}_{current_date.isoformat()}\"\n",
    "\n",
    "#assert not os.path.exists('../models/' + model_name + '.h5'), f\"Model of name {model_name} already exists\"\n",
    "\n",
    "with open('../models/' + model_name + '_config.txt', 'w') as f:\n",
    "        f.write('Input Data:\\n')\n",
    "        [f.write('\\t' + file + '\\n') for file in data_files]\n",
    "        f.write('\\n\\nAugmentation Parameters:\\n')\n",
    "        for k, v in zip(augmentation_parameters.keys(), augmentation_parameters.values()):\n",
    "                f.write(f\"\\t{k}: {v}\\n\")\n",
    "        f.write(f\"\\nBatch Size: {batch_size}\")\n",
    "        f.write(f\"\\nTraining Epochs: {len(train_accuracy)}\")\n",
    "        f.write(f'\\n\\nClassification Report at {threshold}\\n')\n",
    "        f.write(classification_report(y_test, model.predict(x_test) > threshold, \n",
    "                                target_names=['No Mine', 'Mine']))\n",
    "                \n",
    "\n",
    "model.save(f'../models/{model_name}.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model Performance Characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the threshold that maximizes performance on the test set. Note that while this may be the optimum performance on the test set, it does not account for the fact that false positives are functionally worse than false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = model\n",
    "\n",
    "val_images = x_test\n",
    "val_labels = y_test\n",
    "\n",
    "test_preds = test_model.predict(val_images)\n",
    "thresh = []\n",
    "score = []\n",
    "for threshold in range(2, 100, 2):\n",
    "    threshold /= 100\n",
    "    thresh.append(threshold)\n",
    "    test_labels = [np.argmax(y) for y in val_labels]\n",
    "    test_out = [pred > threshold for pred in test_preds]\n",
    "    score.append(1 - (np.sum(np.array(test_labels) != np.array(test_out)[:,0]) / len(test_labels)))\n",
    "    #print(np.sum(np.array(test_labels) != np.array(test_preds)), \"of\", len(test_labels), \"test set predictions incorrect\")\n",
    "plt.plot(thresh, score)\n",
    "plt.ylabel('Success Rate')\n",
    "plt.xlabel('Threshold')\n",
    "plt.title(f\"Optimal Threshold: {thresh[np.argmax(score)]:.2f}\")\n",
    "plt.show()\n",
    "optimal_threshold = thresh[np.argmax(score)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot images that the model classifies incorrectly. Can be useful to evaluate model bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "threshold = 0.8\n",
    "test_model = model\n",
    "val_images = x_test\n",
    "val_labels = y_test\n",
    "test_labels = val_labels\n",
    "test_preds = test_model.predict(val_images)\n",
    "for index, (label, pred, img) in enumerate(zip(test_labels, test_preds, val_images)):\n",
    "    pred = pred[0]\n",
    "    if pred < threshold:\n",
    "        binary_pred = 0\n",
    "    else:\n",
    "        binary_pred = 1\n",
    "    if label != binary_pred:\n",
    "        rgb = (img[:,:,3:0:-1] * 10000 / 3000)\n",
    "        fig = plt.figure(figsize=(2,2), facecolor=(1,1,1), dpi=150)\n",
    "        plt.imshow(np.clip(rgb, 0, 1))\n",
    "        plt.title(f\"label: {label} - pred: {pred:.2f}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('mining-detector')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "bec97cbb607180795486aa419a93884fe3d0b55501c3e5098d64200fe61c3ffb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
